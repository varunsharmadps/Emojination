{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "import gensim\n",
    "import math\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence \n",
    "regex = \"([@][A-Za-z0-9]+)|([^0-9A-Za-z# \\t])|(\\w+:\\/\\/\\S+)|(#[^A-Za-z0-9]+)\"\n",
    "tweets = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../../data/train_semeval2018task2/tweets_us.text', 'r') as file:\n",
    "    for tweet in file:\n",
    "        reg_tweet = ' '.join(re.sub(regex, \" \", tweet).split())\n",
    "        low_tweet = reg_tweet.lower()\n",
    "        tweets.append(low_tweet)\n",
    "with open('../../../data/train_semeval2018task2/tweets_us.labels', 'r') as file:\n",
    "    for label in file:\n",
    "        tweet_label = int(label)\n",
    "        labels.append(tweet_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# max_length = math.ceil(sum([len(s.split(\" \")) for s in tweets])/len(tweets))\n",
    "max_length = 15\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488553, 'encoded doc len')\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='!\"$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', split=\" \",lower=True)\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "encoded_docs = tokenizer.texts_to_sequences(tweets)\n",
    "print(len(encoded_docs), \"encoded doc len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = pad_sequences(encoded_docs[0:300000], maxlen=max_length,padding='post')\n",
    "\n",
    "Ytrain = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for emoji in labels[0:300000]:\n",
    "    num = int(emoji)\n",
    "    bit_vec = np.zeros(20)\n",
    "    bit_vec[num] = 1\n",
    "    Ytrain.append(bit_vec)\n",
    "\n",
    "Ytrain = np.asarray(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 15, 'one')\n",
      "(300000, (20,), array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
      "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.]]), [2, 17, 0, 18, 1], 'two')\n"
     ]
    }
   ],
   "source": [
    "print(len(Xtrain), len(Xtrain[0]), \"one\")\n",
    "print(len(Ytrain), Ytrain[0].shape, Ytrain[0:5], labels[0:5], \"two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xval = pad_sequences(encoded_docs[300000:400000], maxlen=max_length,padding='post')\n",
    "\n",
    "Yval = []#np.asarray([one_hot(emoji, 20) for emoji in labels[-200:]])\n",
    "\n",
    "for emoji in labels[300000:400000]:\n",
    "    num = int(emoji)\n",
    "    bit_vec = np.zeros(20)\n",
    "    bit_vec[num] = 1\n",
    "    Yval.append(bit_vec)\n",
    "\n",
    "Yval = np.asarray(Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print len(Xval)\n",
    "print len(Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = pad_sequences(encoded_docs[400000:488553], maxlen=max_length,padding='post')\n",
    "\n",
    "Ytest = []#np.asarray([one_hot(emoji, 20) for emoji in labels[-200:]])\n",
    "\n",
    "for emoji in labels[400000:488553]:\n",
    "    num = int(emoji)\n",
    "    bit_vec = np.zeros(20)\n",
    "    bit_vec[num] = 1\n",
    "    Ytest.append(bit_vec)\n",
    "\n",
    "Ytest = np.asarray(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88553, array([  271,   296,    24,   677,    11,     3,   365,   258,    32,\n",
      "          25,    17,   247,    44,  3684, 19771], dtype=int32), 15, 'three')\n",
      "(88553, array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.]]), 'four')\n",
      "[[153, 211, 6591, 68], [289, 61, 5, 64, 2488, 16, 1, 647, 2990, 29014], [1518, 40, 7, 3834, 5872, 207, 349], [2489, 9011, 80], [3, 130, 925, 11439, 9]]\n"
     ]
    }
   ],
   "source": [
    "print(len(Xtest), Xtest[0] ,len(Xtest[0]), \"three\")\n",
    "print(len(Ytest), Ytest[0:5], \"four\")\n",
    "print(encoded_docs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index\n",
    "raw_embedding = KeyedVectors.load_word2vec_format('../model_swm_300-6-10-low.w2v', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_map_from_file(path):\n",
    "    map_path = path\n",
    "    input_map = defaultdict(list)\n",
    "    with open(map_path, 'rb') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for l in lines[1:]:\n",
    "            splits = l.decode('utf-8').split('\\t')\n",
    "            input_map[splits[0]] = [float(num) for num in splits[1:]]\n",
    "    return input_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_map = get_map_from_file(\"../../../data/NRC-emotion-lexicon-wordlevel-v0.92_new.txt\")\n",
    "hash_map = get_map_from_file(\"../../../data/NRC-Hashtag-Emotion-Lexicon-v0.2_new_new.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,)\n"
     ]
    }
   ],
   "source": [
    "# print emotion_map['love']\n",
    "# print hash_map['love']\n",
    "# print raw_embedding['love']\n",
    "arr = np.concatenate([emotion_map['love'], hash_map['love'],raw_embedding['love']])\n",
    "print arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ -2.49416304e+00  -2.73652196e+00   1.07892096e+00  -5.90315998e-01\n",
      "  -1.08510004e-02  -3.47730011e-01   6.26335979e-01  -1.07418895e+00\n",
      "  -2.01529408e+00  -2.40448996e-01   2.42495000e-01  -7.84933984e-01\n",
      "  -1.67200196e+00  -4.14879993e-02   9.39583004e-01   3.67273986e-01\n",
      "   5.29563010e-01   3.22743201e+00   1.37507200e+00  -1.42488003e-01\n",
      "  -7.85157979e-01   2.41495997e-01   2.25024000e-01  -3.15144396e+00\n",
      "   1.75267398e+00   3.62899005e-01  -8.62884998e-01  -2.21239999e-01\n",
      "   3.74500990e-01   5.67982972e-01   1.33612800e+00   1.06796002e+00\n",
      "   2.17680097e+00   5.80471992e-01   2.89506602e+00  -4.43657780e+00\n",
      "  -1.81143606e+00  -1.42539299e+00  -4.42034990e-01  -3.90379012e-01\n",
      "  -6.81647003e-01  -5.36056995e-01   1.27458298e+00   3.76769805e+00\n",
      "   1.79887605e+00  -7.45612025e-01   3.76491994e-01  -1.98738205e+00\n",
      "  -1.12538505e+00   2.06403303e+00   7.60254979e-01  -1.79600799e+00\n",
      "   3.32119799e+00  -2.27670789e+00   2.85004997e+00  -1.64883804e+00\n",
      "   1.11431801e+00   1.20338595e+00   8.59320998e-01   1.55377102e+00\n",
      "   2.76660006e-02  -1.71010602e+00   2.76358199e+00  -6.78430021e-01\n",
      "  -1.31981504e+00  -7.33308971e-01  -7.32101023e-01  -1.14518201e+00\n",
      "  -6.36280030e-02   4.31585014e-01   8.49350989e-01  -1.32403004e+00\n",
      "  -3.13854009e-01  -2.77489990e-01  -2.29764000e-01   1.33796000e+00\n",
      "  -1.09661901e+00   5.56474984e-01   6.27506971e-01  -5.04809976e-01\n",
      "  -2.21036696e+00  -1.69589698e+00  -9.46600020e-01  -2.73969197e+00\n",
      "  -1.81204605e+00  -1.51755905e+00   4.42319989e-01  -6.16425991e-01\n",
      "   1.41540002e-02  -1.57165003e+00  -2.01241994e+00  -1.48720896e+00\n",
      "   1.54866898e+00  -1.24743104e+00   2.08729997e-01  -3.87549013e-01\n",
      "   1.00180602e+00   1.39478302e+00  -1.06582201e+00   1.08373404e+00\n",
      "   9.73451018e-01  -9.84588027e-01   1.67560506e+00  -1.86131203e+00\n",
      "   5.25044978e-01  -2.14581800e+00   3.80291998e-01   4.20430005e-01\n",
      "  -2.97589588e+00   2.18603802e+00   5.50917029e-01  -2.39424005e-01\n",
      "  -1.07860696e+00  -4.36605006e-01  -4.38055992e-01   5.83048999e-01\n",
      "   3.60927999e-01   4.02499996e-02   1.34758306e+00  -1.48304105e+00\n",
      "   1.79535198e+00   7.02870011e-01  -2.20910192e+00  -9.83775020e-01\n",
      "  -2.44426996e-01  -9.23947990e-01  -8.43011975e-01  -4.83417004e-01\n",
      "  -7.78353989e-01   8.64650011e-01   2.26956701e+00   7.49207020e-01\n",
      "   6.26042008e-01  -8.54960009e-02  -1.29168403e+00  -4.64148015e-01\n",
      "  -4.38780010e-01   2.31968403e+00  -8.93418014e-01   2.35279012e+00\n",
      "  -6.07038021e-01   2.80620599e+00  -9.81597006e-01   7.75057018e-01\n",
      "  -2.62306988e-01  -7.94004977e-01   8.63129973e-01   6.80970028e-02\n",
      "  -1.02087200e+00   1.66748002e-01  -1.92755795e+00  -1.80988801e+00\n",
      "  -1.69106197e+00  -1.29701996e+00   2.36110210e+00   1.87227499e+00\n",
      "   1.94668901e+00  -5.60495973e-01  -4.55803007e-01  -1.13607001e+00\n",
      "   1.39251101e+00  -2.74201703e+00   1.24285305e+00  -6.38080016e-02\n",
      "   6.95204020e-01  -8.34406018e-01  -2.05094790e+00  -1.52906999e-01\n",
      "  -2.02919197e+00  -1.02076197e+00   5.09109974e-01   5.40395021e-01\n",
      "   7.43869990e-02  -1.71001995e+00  -7.24386990e-01   1.27202499e+00\n",
      "  -8.67353022e-01   2.82984900e+00  -8.53579998e-01  -1.21752001e-01\n",
      "   1.03495705e+00  -3.81219006e+00  -7.58446991e-01   7.75175989e-01\n",
      "   3.41724896e+00  -1.22245002e+00   2.69975007e-01  -1.82411999e-01\n",
      "  -1.87483597e+00   1.44026995e-01   1.38388002e+00   9.38069969e-02\n",
      "  -9.13119972e-01  -9.79929984e-01  -1.46811199e+00  -2.75357008e-01\n",
      "   6.79606974e-01  -1.51894403e+00  -1.18218803e+00   1.42174196e+00\n",
      "   1.06182206e+00   1.02652895e+00  -5.23347974e-01   2.17855501e+00\n",
      "  -1.66087902e+00  -2.20183492e+00  -6.15616024e-01  -3.33103001e-01\n",
      "  -1.73444605e+00  -1.49329305e+00   1.07369196e+00  -1.60392594e+00\n",
      "   9.49944019e-01  -2.56749606e+00   3.22416008e-01   4.27246004e-01\n",
      "   2.35687900e+00   8.31999991e-04   7.09851980e-01  -4.27855998e-01\n",
      "  -3.00862014e-01   2.01839495e+00  -9.39552009e-01  -2.25161099e+00\n",
      "  -1.57123303e+00  -2.53632593e+00  -8.21735978e-01   3.37217402e+00\n",
      "  -7.69463003e-01  -3.47999990e-01   1.10723603e+00   2.21005201e+00\n",
      "  -2.29849505e+00   1.25809705e+00   3.69358003e-01   1.38504195e+00\n",
      "   1.76812100e+00   3.53572994e-01   1.17691302e+00  -3.59774399e+00\n",
      "   1.65604699e+00  -8.86964023e-01   6.27737999e-01   2.61475706e+00\n",
      "  -6.08434975e-01   1.04189001e-01  -2.59434509e+00   7.74713993e-01\n",
      "   3.59759986e-01  -8.88049006e-01   8.85457993e-01  -7.65818000e-01\n",
      "   1.34644198e+00   8.39890018e-02  -2.36010289e+00   2.08603597e+00\n",
      "  -7.31070995e-01   2.28431606e+00  -2.90977192e+00   9.74793971e-01\n",
      "  -5.42630017e-01  -1.27284896e+00  -2.67699994e-02   8.96205008e-01\n",
      "  -1.39557099e+00   1.13227701e+00   2.22734189e+00  -4.01610994e+00\n",
      "  -3.45867991e-01   2.82486391e+00   2.35775089e+00   1.21962798e+00\n",
      "   4.29466915e+00  -1.00804198e+00   2.02907801e+00   2.78065705e+00\n",
      "   2.11745501e+00   1.68616903e+00   2.11295104e+00   1.93480396e+00\n",
      "  -1.59320402e+00   3.29908997e-01  -2.96508408e+00   1.07952201e+00\n",
      "  -1.24345005e+00   4.23440993e-01   1.28295195e+00  -3.96674204e+00\n",
      "   2.39603400e+00   7.58323014e-01   2.04058006e-01   5.24909973e-01\n",
      "  -1.14776504e+00  -1.94795799e+00   7.72934973e-01   2.08987403e+00\n",
      "  -9.71747994e-01   1.36261499e+00   1.06620002e+00   5.33689976e-01\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.91983879e-03   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab) + 1\n",
    "weight_matrix = np.zeros((vocab_size, 320))\n",
    "print(weight_matrix[17])\n",
    "for word, i in vocab.items():\n",
    "    #if word in raw_embedding2:\n",
    "    #    weight_matrix[i] = raw_embedding2[word]\n",
    "    emotion_val = np.zeros(10)\n",
    "    hash_val = np.zeros(10)\n",
    "    embedding = np.zeros(300)\n",
    "    if word in emotion_map:\n",
    "        emotion_val = emotion_map[word]\n",
    "    if word in hash_map:\n",
    "        hash_val = hash_map[word]\n",
    "    if word in raw_embedding:\n",
    "        embedding = raw_embedding[word]\n",
    "    final = np.concatenate([embedding, emotion_val, hash_val])\n",
    "    weight_matrix[i] = final\n",
    "print(weight_matrix[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, 320, weights=[weight_matrix], input_length=max_length, trainable=False,\n",
    "                            mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2)))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300000 samples, validate on 100000 samples\n",
      "Epoch 1/4\n",
      "299968/300000 [============================>.] - ETA: 0s - loss: 2.2422 - acc: 0.3358Epoch 00001: val_loss improved from inf to 2.16820, saving model to weights.hdf5\n",
      "300000/300000 [==============================] - 1153s 4ms/step - loss: 2.2422 - acc: 0.3358 - val_loss: 2.1682 - val_acc: 0.3535\n",
      "Epoch 2/4\n",
      "299968/300000 [============================>.] - ETA: 0s - loss: 2.1453 - acc: 0.3595Epoch 00002: val_loss improved from 2.16820 to 2.13936, saving model to weights.hdf5\n",
      "300000/300000 [==============================] - 1193s 4ms/step - loss: 2.1453 - acc: 0.3595 - val_loss: 2.1394 - val_acc: 0.3614\n",
      "Epoch 3/4\n",
      "299968/300000 [============================>.] - ETA: 0s - loss: 2.0982 - acc: 0.3703Epoch 00003: val_loss improved from 2.13936 to 2.13042, saving model to weights.hdf5\n",
      "300000/300000 [==============================] - 1110s 4ms/step - loss: 2.0983 - acc: 0.3703 - val_loss: 2.1304 - val_acc: 0.3621\n",
      "Epoch 4/4\n",
      "299968/300000 [============================>.] - ETA: 0s - loss: 2.0641 - acc: 0.3786- ETA: 0s - loss: 2.0640 - acc: 0.37Epoch 00004: val_loss did not improve\n",
      "300000/300000 [==============================] - 1059s 4ms/step - loss: 2.0640 - acc: 0.3787 - val_loss: 2.1315 - val_acc: 0.3629\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(Xtrain, \n",
    "                 Ytrain,\n",
    "                 epochs=3,\n",
    "                 batch_size=64,\n",
    "                 validation_data=(Xval, Yval), \n",
    "                 callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights.hdf5')\n",
    "predicted = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88553/88553 [==============================] - 123s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12229707361\n",
      "0.365001750365\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
